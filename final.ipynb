{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f283b87e",
   "metadata": {},
   "source": [
    "# Galaxy Classification using Supervised Learning with Deep Convolutional Neural Networks for Multi-Class Image Classification\n",
    "## Group 7 AI Class Final Projects\n",
    "Members:\n",
    "- Abi\n",
    "- Gavin\n",
    "- Rasyid\n",
    "- Hikmal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3d6ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa8bb8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1acb4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change/add any additional imports here\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7edc04",
   "metadata": {},
   "source": [
    "### Data Wrangling & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e00b43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PGC_name  PGC_no     vrad  e_vrad     vopt  e_vopt        v   e_v  \\\n",
      "0  PGC0000212   212.0  11230.4     4.5  11110.0    47.0  11229.3   9.0   \n",
      "1  PGC0000218   218.0   1050.3     4.8   1027.4    25.0   1049.5   4.5   \n",
      "2  PGC0000243   243.0  -9999.0 -9999.0   8914.3    16.3   8914.3  16.3   \n",
      "3  PGC0000255   255.0    878.1     4.1  -9999.0 -9999.0    878.1   4.1   \n",
      "4  PGC0000281   281.0  -9999.0 -9999.0  11490.7    16.4  11490.7  16.4   \n",
      "\n",
      "      vvir      zvir     z_err type    objname            hl_names  \n",
      "0  11287.9  0.037650  0.000030  Sab     IC5381           PGC000212  \n",
      "1   1109.0  0.003699  0.000015  Sab    NGC7814          PGC1501809  \n",
      "2   8841.8  0.029490  0.000054   S0    NGC7808  6dFJ0003321-104441  \n",
      "3    932.9  0.003112  0.000014   Sm   UGC00017           PGC000255  \n",
      "4  11416.0  0.038080  0.000055   Sc  PGC000281       MCG-02-01-015  \n",
      "\n",
      "unique classes:\n",
      "['Sab' 'S0' 'Sm' 'Sc' 'Sa' 'Sd' 'SBa' 'IB' 'Sb' 'SABc' 'SBc' 'SBb' 'Scd'\n",
      " 'S0-a' 'I' 'SBbc' 'SBd' 'E' 'SBm' 'SABa' 'SABb' '|' 'E-SO' 'Sbc' 'SABm'\n",
      " 'SBab' 'SBcd' 'IAB' 'SABd' 'S?']\n",
      "major_class\n",
      "S        1860\n",
      "SB       1153\n",
      "E        1097\n",
      "Other     348\n",
      "Name: count, dtype: int64\n",
      "      PGC_name major_class\n",
      "0   PGC0000212           S\n",
      "1   PGC0000218           S\n",
      "2   PGC0000243           E\n",
      "3   PGC0000255           S\n",
      "4   PGC0000281           S\n",
      "5   PGC0000282           S\n",
      "6   PGC0000451           S\n",
      "7   PGC0000548           S\n",
      "8   PGC0000635          SB\n",
      "9   PGC0000639           S\n",
      "10  PGC0000647       Other\n",
      "11  PGC0000670           S\n",
      "12  PGC0000825           S\n",
      "13  PGC0000963          SB\n",
      "14  PGC0001058           S\n",
      "      PGC_name major_class\n",
      "0   PGC0000212           S\n",
      "1   PGC0000218           S\n",
      "2   PGC0000243           E\n",
      "3   PGC0000255           S\n",
      "4   PGC0000281           S\n",
      "5   PGC0000282           S\n",
      "6   PGC0000451           S\n",
      "7   PGC0000548           S\n",
      "8   PGC0000635          SB\n",
      "9   PGC0000639           S\n",
      "10  PGC0000670           S\n",
      "11  PGC0000825           S\n",
      "12  PGC0000963          SB\n",
      "13  PGC0001058           S\n",
      "14  PGC0001221          SB\n"
     ]
    }
   ],
   "source": [
    "#Process the labels first\n",
    "def major_class(t):\n",
    "    t = str(t).strip()\n",
    "    if t.startswith(\"E\"):\n",
    "        return \"E\"\n",
    "    elif t.startswith(\"S0\"):\n",
    "        return \"E\" #S0 is closer to E (Lenticular)\n",
    "    elif t.startswith(\"SAB\"):\n",
    "        return \"SB\" #SAB is closer to SB (Barred Spiral)\n",
    "    elif t.startswith(\"SB\"):\n",
    "        return \"SB\"\n",
    "    elif t.startswith(\"S\"):\n",
    "        return \"S\"\n",
    "    else:\n",
    "        return \"Other\"  #Catchall for irregular/unknown types\n",
    "\n",
    "df = pd.read_csv('efigiuse/label.csv')\n",
    "print(df.head())\n",
    "print(\"\\nunique classes:\")\n",
    "print(df[\"type\"].unique()) #Checking the unique classes\n",
    "df[\"major_class\"] = df[\"type\"].apply(major_class)\n",
    "print(df[\"major_class\"].value_counts()) #Checking the number of major classes\n",
    "\n",
    "#Create new dataframe with only PGC_name and major_class columns\n",
    "df_major = df[[\"PGC_name\", \"major_class\"]]\n",
    "print(df_major.head(15)) #df_major at a glance\n",
    "\n",
    "#Create a filtered version of df_major (\"Other\" class removed)\n",
    "df_use = df_major[df_major[\"major_class\"] != \"Other\"].reset_index(drop=True)\n",
    "print(df_use.head(15)) #df_use at a glance\n",
    "\n",
    "#Label processing complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e578b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['E' 'S' 'SB']\n"
     ]
    }
   ],
   "source": [
    "#Image processing\n",
    "image_dir = \"efigiuse/png/\"\n",
    "image_size = (255, 255)\n",
    "X, y = [], [] #Initialize empty lists for images and labels\n",
    "for idx, row in df_use.iterrows():\n",
    "    image_path = os.path.join(image_dir, f\"{row['PGC_name']}.png\")\n",
    "    if os.path.exists(image_path):\n",
    "        img = load_img(image_path, target_size=image_size)\n",
    "        img_array = img_to_array(img) / 255.0  #Normalization to [0, 1]\n",
    "        X.append(img_array) #X is for the images\n",
    "        y.append(row[\"major_class\"]) #y is for the labels\n",
    "    else:\n",
    "        print(f\"Missing image: {image_path}\")\n",
    "#No images should be missing. If any are, check efigiuse/png/ and redownload the images from: \n",
    "#https://www.astromatic.net/download/efigi/efigi_png_gri-1.6.tgz\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y) #Label encoding\n",
    "print(\"Classes: \" + str(encoder.classes_)) #Checking the classes, should be [\"E\", \"S\", \"SB\"]\n",
    "\n",
    "#Train, validation, and test split\n",
    "X = np.array(X) #Convert X & y to numpy arrays\n",
    "y_encoded = np.array(y_encoded)\n",
    "#Train (70%) - Rest (30%) split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_encoded, test_size=0.30, random_state=42, stratify=y_encoded)\n",
    "#Validation (15%) - Test (15%) split\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "\n",
    "#Training data augmentation to prevent overfitting\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9cccf",
   "metadata": {},
   "source": [
    "### CNN Architecture Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6095247c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/labt1/gavin/aiprojects/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Volumes/labt1/gavin/aiprojects/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 6s/step - accuracy: 0.4986 - loss: 1.4601 - val_accuracy: 0.2532 - val_loss: 6.3451\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 6s/step - accuracy: 0.5456 - loss: 1.1827 - val_accuracy: 0.2662 - val_loss: 8.9002\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 6s/step - accuracy: 0.5815 - loss: 1.0449 - val_accuracy: 0.2662 - val_loss: 6.9831\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 6s/step - accuracy: 0.5670 - loss: 1.0757 - val_accuracy: 0.5032 - val_loss: 3.7792\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 6s/step - accuracy: 0.5805 - loss: 1.0116 - val_accuracy: 0.2906 - val_loss: 3.0334\n",
      "Epoch 6/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m781s\u001b[0m 9s/step - accuracy: 0.6015 - loss: 0.9653 - val_accuracy: 0.5909 - val_loss: 0.9777\n",
      "Epoch 7/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 5s/step - accuracy: 0.6062 - loss: 0.9343 - val_accuracy: 0.5958 - val_loss: 0.9532\n",
      "Epoch 8/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 5s/step - accuracy: 0.6111 - loss: 0.9229 - val_accuracy: 0.5893 - val_loss: 0.9592\n",
      "Epoch 9/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 6s/step - accuracy: 0.6084 - loss: 0.9126 - val_accuracy: 0.6185 - val_loss: 0.9007\n",
      "Epoch 10/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 6s/step - accuracy: 0.6156 - loss: 0.9159 - val_accuracy: 0.6218 - val_loss: 0.8956\n",
      "Epoch 11/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 5s/step - accuracy: 0.6153 - loss: 0.9042 - val_accuracy: 0.5617 - val_loss: 1.0114\n",
      "Epoch 12/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 5s/step - accuracy: 0.6233 - loss: 0.9033 - val_accuracy: 0.6023 - val_loss: 0.9723\n",
      "Epoch 13/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 5s/step - accuracy: 0.6307 - loss: 0.8578 - val_accuracy: 0.6153 - val_loss: 0.9361\n",
      "Epoch 14/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 5s/step - accuracy: 0.6177 - loss: 0.8992 - val_accuracy: 0.5617 - val_loss: 1.4541\n",
      "Epoch 15/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 5s/step - accuracy: 0.6085 - loss: 0.9058 - val_accuracy: 0.6006 - val_loss: 0.9489\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df_use[\"major_class\"].unique()); print(\"Number of classes: \" + str(num_classes)) #Checking the number of classes\n",
    "#Current arrays are integer coded (0,1,2). Convert to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "weight_decay = 1e-4 #L2 regularization parameter\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(weight_decay), input_shape=(255, 255, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),  #Prevents overfitting\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_val, y_val), epochs=30, callbacks=[early_stop])\n",
    "\n",
    "#WARNING: MAKE SURE TO HAVE A GENUINELY GOOD COMPUTING SETUP WITH MAXIMUM COOLING AND POWER BEFORE EXECUTING\n",
    "#DO NOT LET YOUR MACHINE GET OVERHEATED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6217ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.6059 - loss: 0.9008\n",
      "Test Accuracy: 0.6207\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 900ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78       165\n",
      "           1       0.62      0.67      0.65       279\n",
      "           2       0.46      0.28      0.35       173\n",
      "\n",
      "    accuracy                           0.62       617\n",
      "   macro avg       0.59      0.61      0.59       617\n",
      "weighted avg       0.60      0.62      0.60       617\n",
      "\n",
      "[[147  11   7]\n",
      " [ 42 187  50]\n",
      " [ 22 102  49]]\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "print(confusion_matrix(y_true, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiprojects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
